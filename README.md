<center>
    <img src="data:image/png;base64,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" alt="Logo Sauter" style="zoom:100%;" />
</center>

# Desafio: Capturar dados de Loja de Aplicativo - Google Play

## Tópicos:
- [Descrição do projeto](#descrição-do-projeto)
- [Objetivos](#objetivos)
- [Deploy da Aplicação](#deploy-da-aplicação)
- [Pré-requisitos](#pré-requisitos)
- [Como rodar a aplicação](#como-rodar-a-aplicação)
- [Linguagens, dependencias e libs utilizadas](#linguagens-dependencias-e-libs-utilizadas)
- [Tarefas em aberto](#tarefas-em-aberto)

------

## Descrição do projeto
O Desafio Python tem como objetivo reflitir alguns desafios que um Engenheiro de Dados possa enfrentar na [Sauter](https://sauter.digital/).

⚠ É importante saber que há múltiplos formatos para a resolução do desafio e será necessário consultar documentações (algumas das quais colocaremos o link aqui).

------

## Objetivos

### Tarefa 1: 
Sua primeira tarefa é utilizar a library google-play-scraper para capturar dados de apps.
O app selecionado é o [Alexa](https://play.google.com/store/apps/details?id=com.amazon.dee.app), da Amazon.

1. ✅ Utilizando as informações de avaliação do aplicativo, você deve chegar em um Data Frame de review parecido com o demonstrado abaixo:

<img scr="img/df_example.png" alt="DataFrame_Example" /></br>

A partir desse Data Frame, seguem as atividades propostas na tarefa:

2.  ✅ Criar 3 arquivos .csv a partir do dataframe, com a seguinte classificação:
    1. aval_positiva.csv para score maior ou igual a 4; 
    2. aval_neutra.csv para score igual a 3;
    3. aval_negativa.csv para score inferior a 3.

3.  ✅ Criar um report simples para essas variáveis utilizando a library pandas profiling para
cada uma das separações (aval_neutra, aval_positiva, aval_negativa). </br>
⚠ É importante notar os principais pontos de cada análise para sua apresentação.</br>
Finalmente, salvar o resultado do profile em formato .html.

### Tarefa 2: 
1. ⬜ A partir dos dados criados, subir as tabelas para um banco de dados.
 Aqui é completamente opcional qual banco de dados utilizar, mas considerar utilizar o [BigQuery](https://cloud.google.com/bigquery/docs/tables) da Google, pois é totalmente gratuito (para o tamanho do dataset) e em cloud.

    ⚠ Caso prefira utilizar outro banco de dados de seu domínio também vale como problema resolvido.

### Tarefa 3: 
1. Criar objeto com operações de captura de dados, com atualização da tabela. O objetivo aqui é criar um pipeline simplificado de dados para o banco, de forma que a tabela seja sempre atualizada com as últimas informações de reviews.

------

## Pré-requisitos


------

## Como rodar a aplicação

Tarefa 1 - Capturar dados de Loja de Aplicativo - Google Play
1. Acessar o Google Colab - https://colab.research.google.com/drive/1ak9TAlvzWBj5Hh39swM8iG-uF1dVaDe6?usp=sharing
2. Acessar o arquivo [google-play-scraper-alexa.ipynb]()

Tarefa 2 - Subir as tabelas para um BD

Tarefa 3 - Criar Pipeline de dados

------

## Linguagens, dependencias e libs utilizadas

|Lang/Lib/Framwork    |Version          |
|---------------------|---------        |
|Python               |3.6, 3.7 ou 3.8  |
|Google-Play-Scraper  |v1.0.2           |
|Pandas Profiling     |v3.1.0           |


------
## Referências

- [google-play-scraper 1.0.2](https://pypi.org/project/google-play-scraper/)
- [Pandas API reference](https://pandas.pydata.org/docs/reference/)
- [Package pandas_profiling](https://pandas-profiling.github.io/pandas-profiling/docs/master/index.html) 